import streamlit as st
from langchain.schema import HumanMessage, SystemMessage, AIMessage, BaseMessage
import mysql.connector
from mysql.connector import Error
import json
import hashlib
import os
import pandas as pd
import plotly.graph_objects as go
from decimal import Decimal, ROUND_HALF_UP
import plotly.graph_objects as go
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain, LLMChain
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.utilities import DuckDuckGoSearchAPIWrapper
from langchain.prompts import PromptTemplate
import requests
from bs4 import BeautifulSoup
import re
import asyncio
from PIL import Image
import torch
from typing import List
from transformers import pipeline
from duckduckgo_search import DDGS
from requests.exceptions import HTTPError
from langchain_ollama import ChatOllama
from contents import LLM
import asyncio


async def handle_query(prompt, query_chain,question_chain, search, extract_urls, get_webpage_content, chat_history, image_file=None, imageflag=None):
    try:
        chain = ConversationChain(
            llm=st.session_state.llm,
            memory=st.session_state.memory,
            verbose=True
        )
        # ç”»åƒãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹å ´åˆ
        if image_file is not None:
            #comment_prompt = f"ã“ã®ç”»åƒã«é–¢ã™ã‚‹è³ªå•/ã‚³ãƒ¡ãƒ³ãƒˆï¼š{prompt}" if prompt is not None else ""
            # å‰å›ã®ç”»åƒã¨ç•°ãªã‚‹å ´åˆã¯ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆã—ã¦ä¼šè©±
            if imageflag:
                # ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ç”Ÿæˆ
                with st.spinner('ç”»åƒã‚’è§£æä¸­...'):
                    caption = generate_image_caption(image_file)
                st.info(f"ç”»åƒã®èª¬æ˜: {caption}")
                
                # prompt_with_image = f"""ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åŸºã¥ã„ãŸç°¡å˜ãªè‹±ä¼šè©±ã‚’ã‚ãªãŸã¨ã—ãŸã„ã§ã™ã€‚
                # ä»¥ä¸‹ã«ä¾‹ã‚’å¼µã‚Šã¾ã™ã€‚ä¾‹ãªã®ã§çŒ«ãªã©ã®å†…å®¹ã¯ç„¡è¦–ã—ã¦ãã ã•ã„ã€‚\n
                # A: Look at the cat! It's sitting on the floor in front of the kitchen. (è¦‹ã¦ï¼çŒ«ãŒã‚­ãƒƒãƒãƒ³ã®å‰ã®åºŠã«åº§ã£ã¦ã‚‹ã‚ˆã€‚)\n
                # B: Yeah, it looks so relaxed! (ã‚ã‚ã€ã¾ã£ãŸã‚Šã—ã¦ã‚‹ã­ï¼)\n
                # A: I know, right? Maybe it's waiting for food. (ãã†ã ã‚ˆã­ï¼Ÿã‚‚ã—ã‹ã—ãŸã‚‰ã”é£¯ãŒé£Ÿã¹ãŸã„ã‹ã‚‰å¾…ã£ã¦ã‚‹ã®ã‹ãªã€‚)\n
                # B: Do you think the cat is hungry? (çŒ«ã¯ãŠãªã‹ã™ã„ã¦ã‚‹ã‹ãªï¼Ÿ)\n
                # A: Hmm, maybe. Cats love food! (ãˆãƒ¼ã€ã‚‚ã—ã‹ã—ãŸã‚‰ã€‚çŒ«ã¯é£Ÿã¹ç‰©ãŒå¤§å¥½ããªã‚“ã ã‚ˆï¼)\n\n
                # Question: What do you think the cat would say if it could talk? (çŒ«ãŒè©±ã™ã“ã¨ãŒã§ããŸã‚‰ä½•ã¨è¨€ã†ã‹ãªï¼Ÿ)\n
                
                # ä¸Šè¨˜ã®ã‚ˆã†ã«ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦ä½•å›ã‹æ—¥æœ¬èªè¨³ã‚’ã¤ã‘ãŸè‹±ä¼šè©±ã‚’ã—ãŸã†ãˆã§ã€æœ€å¾Œã«æ—¥æœ¬èªè¨³ã‚’ã¤ã‘ãŸè‹±èªã§ç§ã«ä½•ã‹è³ªå•ã‹å•ã„ã‹ã‘ã‚’ã—ã¦ãã ã•ã„ã€‚ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼š
                # {caption}

                # """
                prompt_with_image = f"""
                ä»¥ä¸‹ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ä½¿ã£ãŸæ—¥æœ¬èªè¨³ä»˜ãã®ç°¡å˜ãªè‹±ä¼šè©±ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚  
                1. **ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«é–¢é€£ã—ãŸ1ã¤ã®çŸ­ã„è‹±èªã®æ–‡**ï¼ˆæ—¥æœ¬èªè¨³ã‚’æ·»ãˆã‚‹ã“ã¨ï¼‰ã€‚  
                2. **ãã®æ–‡ã«åŸºã¥ã„ãŸã€è‹±èªã®è³ªå•ã‚’1ã¤**ï¼ˆæ—¥æœ¬èªè¨³ã‚’æ·»ãˆã‚‹ã“ã¨ï¼‰ã€‚  

                ä¾‹ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: çŒ«ï¼‰:  
                è‹±èª: Look at the cat! It's sitting on the floor in front of the kitchen. \n 
                æ—¥æœ¬èªè¨³: è¦‹ã¦ï¼çŒ«ãŒã‚­ãƒƒãƒãƒ³ã®å‰ã®åºŠã«åº§ã£ã¦ã‚‹ã‚ˆã€‚  \n

                è³ªå•: What do you think the cat would say if it could talk?  \n
                æ—¥æœ¬èªè¨³: çŒ«ãŒè©±ã™ã“ã¨ãŒã§ããŸã‚‰ä½•ã¨è¨€ã†ã‹ãªï¼Ÿ  \n

                ä»¥ä¸‹ã®å½¢å¼ã«å¾“ã£ã¦ä½œæˆã—ã¦ãã ã•ã„ã€‚  

                ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {caption}  
                """
                
                #response = await st.session_state.llm.apredict(prompt_with_image)
                reply = chain.invoke(prompt_with_image)
                #reply = await chain.ainvoke(prompt_with_image)
                response = reply['response']
                await chat_history.add_message(prompt_with_image, is_bot=False)
                await chat_history.add_message(response, is_bot=True)
                st.session_state['questionprompt'] = response
                st.session_state['previous_uploaded_file'] = image_file
                # analysis = await question_chain.ainvoke(st.session_state.get('questionprompt', ''))
                analysis = question_chain.invoke(st.session_state.get('questionprompt', ''))
                content = analysis.content if hasattr(analysis, 'content') else str(analysis)
                st.session_state['needs_question'] = "NEEDS_QUESTION: true" in content
                if st.session_state['needs_question']:
                    question_query = re.search(r'QUESTION_QUERY: (.*)', content)
                    st.session_state['question_query'] = question_query.group(1)
                    st.session_state['needs_question'] = False
                
            else:
                st.markdown("Question")
                if st.session_state['question_query']:
                    st.markdown(f"{st.session_state['question_query']}")
                # åŒã˜ç”»åƒã®å ´åˆã¯è‹±ä¼šè©±ã®æ­£èª¤åˆ¤å®šã‚µãƒãƒ¼ãƒˆ
                # prompt_with_support = f"""
                
                # ã‚ãªãŸã®ç›®æ¨™ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ¥½ã—ãè‹±ä¼šè©±ã‚’ç·´ç¿’ã—ã€ä¸Šé”ã§ãã‚‹ã‚ˆã†ã«ã‚µãƒãƒ¼ãƒˆã™ã‚‹ã“ã¨ã§ã™ã€‚
                # æ¬¡ã®æ–‡ç« ã®è‹±èªã®æ­£ã—ã•ã‚’æ—¥æœ¬èªã§è©•ä¾¡ã—ã€ã‚ã£ã¦ã„ã‚‹å ´åˆã¯è¤’ã‚ã¦ãã ã•ã„ã€‚
                # è‹±èªã§ã¯ãªã„å ´åˆã‚„é–“é•ã£ã¦ã„ã‚‹å ´åˆã¯ä¿®æ­£ã‚’ææ¡ˆã—ã€ä¿®æ­£ã—ãŸè‹±èªã‚’è©±ã—ã¦ãã ã•ã„ã€‚
                # ã¾ãŸãã®å¾Œã‚‚ä¼šè©±ã‚’ç¶šã‘ã¾ã™ã€‚\n
                # ä»¥ä¸‹ã«ä¾‹ã‚’å¼µã‚Šã¾ã™ã€‚ä¾‹ãªã®ã§å²©ã®å´–ãªã©ã®å†…å®¹ã¯ç„¡è¦–ã—ã¦ãã ã•ã„ã€‚\n
                # Question: What do you think is the most beautiful rocky cliff with a body of water in the world?\n
                # ä¸Šè¨˜ã®ã‚ˆã†ã«æ—¥æœ¬èªè¨³ã‚’ã¤ã‘ãŸè‹±èªã§ç§ã«ä½•ã‹è³ªå•ã‹å•ã„ã‹ã‘ã‚’ã—ã¦ãã ã•ã„ã€‚
                # å‰å›ã®å‡ºåŠ›ã§æ¬¡ã®ã‚ˆã†ãªä¼šè©±ã‚’è¡Œã„ã¾ã—ãŸã€‚ï¼š{st.session_state.get('questionprompt', '')}\n
                # è³ªå•ã®å›ç­”: {prompt}"""
                prompt_with_support = f"""
                ã‚ãªãŸã®ç›®æ¨™ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ¥½ã—ãè‹±ä¼šè©±ã‚’ç·´ç¿’ã—ã€ä¸Šé”ã§ãã‚‹ã‚ˆã†ã«ã‚µãƒãƒ¼ãƒˆã™ã‚‹ã“ã¨ã§ã™ã€‚
                ä¼šè©±ã®æ–‡è„ˆã‚’èª­ã¿å–ã‚Šã€æ¬¡ã®è³ªå•ã®å›ç­”ã®æ–‡ç« ã®è‹±èªã®æ­£ã—ã•ã‚’æ—¥æœ¬èªã§è©•ä¾¡ã—ã€ã‚ã£ã¦ã„ã‚‹å ´åˆã¯ã€ã©ã®éƒ¨åˆ†ãŒè‰¯ã„ã‹å…·ä½“çš„ã«è¤’ã‚ã¦ãã ã•ã„ã€‚
                è‹±èªã§ã¯ãªã„å ´åˆã‚„æ–‡è„ˆçš„ã«é–“é•ã£ã¦ã„ã‚‹å ´åˆã‚„çŸ­ã™ãã¦æ–‡ç« ã¨ã—ã¦è¶³ã‚Šãªã„å ´åˆã¯ã€ã©ã®ç‚¹ãŒå•é¡Œã‹ã‚’ç°¡æ½”ã«èª¬æ˜ã—ã€ä¿®æ­£æ¡ˆã‚’æ—¥æœ¬èªã§ææ¡ˆã—ãŸå¾Œã€ä¿®æ­£ã—ãŸè‹±èªã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚
                "è©•ä¾¡ã¯å¿…ãšæ—¥æœ¬èªã§ã‚ã‹ã‚Šã‚„ã™ãè¨˜è¿°ã—ã¦ãã ã•ã„ã€‚"
                ã¾ãŸã€ãã®å¾Œã‚‚ä¼šè©±ã‚’ç¶šã‘ã¾ã™ã€‚ä¸‹è¨˜ã®ã‚ˆã†ã«æ—¥æœ¬èªè¨³ã‚’ã¤ã‘ãŸè‹±èªã§ç§ã«ä½•ã‹è³ªå•ã‹å•ã„ã‹ã‘ã‚’ã—ã¦ãã ã•ã„ã€‚

                ä»¥ä¸‹ã«ä¾‹ã‚’å¼µã‚Šã¾ã™ã€‚ä¾‹ãªã®ã§ç¾Šãªã©ã®å†…å®¹ã¯ç„¡è¦–ã—ã¦ãã ã•ã„ã€‚:
                
                ã‚ãªãŸã®å›ç­” "sheep's dreams is flying sky" ã«ã¤ã„ã¦ã¯ã€ã„ãã¤ã‹å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚

                **å•é¡Œç‚¹:**

                * **æ–‡æ³•çš„ã‚¨ãƒ©ãƒ¼:** "sheep's dreams is" ã¯æ–‡æ³•çš„ã«æ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚ä¸»èªãŒè¤‡æ•°å½¢ãªã®ã§ã€å‹•è©ã‚‚è¤‡æ•°å½¢ã«ã—ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚ã¤ã¾ã‚Šã€"sheep's dreams are" ã«ãªã‚Šã¾ã™ã€‚
                * **å˜èªã®é¸æŠ:** "flying sky" ã¨ã„ã†è¡¨ç¾ã¯ã€æ„å‘³ã¨ã—ã¦ã¯ç†è§£ã§ãã¾ã™ãŒã€è‡ªç„¶ãªè‹±èªã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚å¤¢ã®ä¸­ã§é£›ã‚“ã§ã„ã‚‹ã“ã¨ã‚’è¡¨ç¾ã—ãŸã„å ´åˆã¯ã€"flying in the sky" ã¾ãŸã¯ "soaring through the air" ãªã©ã®è¡¨ç¾ãŒã‚ˆã‚Šé©ã—ã¦ã„ã¾ã™ã€‚

                **ä¿®æ­£æ¡ˆ:**

                Sheep's dreams are flying in the sky.

                ã“ã‚Œã‚’è‹±è¨³ã™ã‚‹ã¨ï¼š ç¾Šã®å¤¢ã®ä¸­ã§ã¯ç©ºä¸­ã‚’é£›ã‚“ã§ã„ã‚‹ã‚ˆã†ã§ã™ã€‚

                ã•ã¦ã€ç§ã‹ã‚‰æ¬¡ã®è³ªå•ã§ã™ï¼šWhat is the most memorable dream you had while you were sleeping?ï¼ˆã‚ãªãŸã¯çœ ã£ã¦ã„ã‚‹é–“ã«çµŒé¨“ã—ãŸä¸€ç•ªå°è±¡ã«æ®‹ã‚‹å¤¢ã«ã¤ã„ã¦ã¯ä½•ã§ã™ã‹ï¼Ÿï¼‰

                
                å‰å›ã®å‡ºåŠ›ã§æ¬¡ã®ã‚ˆã†ãªä¼šè©±ã‚’è¡Œã„ã¾ã—ãŸï¼š{st.session_state.get('questionprompt', '')}
                è³ªå•ã®å›ç­”: {prompt}
                """
                
                #response = await st.session_state.llm.apredict(prompt_with_support)
                reply = chain.invoke(prompt_with_support)
                #reply = asyncio.run(chain.ainvoke(prompt_with_support))
                response = reply['response']
                st.session_state['questionprompt'] = response
                await chat_history.add_message(prompt_with_support, is_bot=False)
                await chat_history.add_message(response, is_bot=True)
                analysis = question_chain.invoke(response)
                #analysis = await question_chain.ainvoke(response)
                content = analysis.content if hasattr(analysis, 'content') else str(analysis)
                st.session_state['needs_question'] = "NEEDS_QUESTION: true" in content
                if st.session_state['needs_question']:
                    question_query = re.search(r'QUESTION_QUERY: (.*)', content)
                    st.session_state['question_query'] = question_query.group(1)
                    st.session_state['needs_question'] = False
        else:
            # é€šå¸¸ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ã®å‡¦ç†
            #recent_history = await chat_history.get_recent_history()
            # analysis = await query_chain.ainvoke(prompt)
            analysis = query_chain.invoke(prompt)
            content = analysis.content if hasattr(analysis, 'content') else str(analysis)
            needs_search = "NEEDS_SEARCH: true" in content
            has_url = "HAS_URL: true" in content

            if has_url:
                urls = extract_urls(prompt)
                if urls:
                    webpage_content = get_webpage_content(urls[0])
                    prompt_with_content = f"ä»¥ä¸‹ã®Webãƒšãƒ¼ã‚¸ã®å†…å®¹ã«åŸºã¥ã„ã¦é©åˆ‡ãªè¿”ç­”ã‚’è€ƒãˆã¦ãã ã•ã„ã€‚åºƒå‘Šã‚„é–¢é€£è¨˜äº‹ãªã©ã«æ°—ã‚’å–ã‚‰ã‚Œãªã„ã§ãã ã•ã„ã€‚\n\nWebãƒšãƒ¼ã‚¸å†…å®¹: {webpage_content}\n\nè³ªå•: {prompt}"
                    #response = await st.session_state.llm.apredict(prompt_with_content)
                    #response = await chain.ainvoke(prompt_with_content)
                    # reply = await chain.ainvoke(prompt_with_content)
                    reply = chain.invoke(prompt_with_content)
                    response = reply['response']
            elif needs_search:
                st.markdown("""DuckDuckGoã§æ¤œç´¢ä¸­...""")
                search_query = re.search(r'SEARCH_QUERY: (.*)', content)
                if search_query:
                    search_results = search.run(search_query.group(1))
                    prompt_with_search = f"""ä»¥ä¸‹ã®æ¤œç´¢çµæœã®å†…å®¹ã«åŸºã¥ã„ã¦é©åˆ‡ãªè¿”ç­”ã‚’è€ƒãˆã¦ãã ã•ã„ã€‚åºƒå‘Šã‚„é–¢é€£è¨˜äº‹ãªã©ã«æ°—ã‚’å–ã‚‰ã‚Œãªã„ã§ãã ã•ã„ã€‚
                    ã§ãã‚‹ã ã‘æœ€æ–°ã®æƒ…å ±ã‚’å«ã‚ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚

                    æ¤œç´¢çµæœ: {search_results}

                    è³ªå•: {prompt}
                    """
                    
                    #response = await st.session_state.llm.apredict(prompt_with_search)
                    reply = chain.invoke(prompt_with_search)
                    #reply = await chain.ainvoke(prompt_with_search)
                    response = reply['response']
                else:
                    response = "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€‚æ¤œç´¢ã‚¯ã‚¨ãƒªã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚"
            else:
                #st.markdown(st.session_state.memory)
                #reply = await chain.ainvoke(prompt)
                reply = chain.invoke(prompt)
                response = reply['response']

        # å¿œç­”ã®è¡¨ç¤º
        with st.chat_message("assistant"):
            st.markdown(response)
        st.session_state.messages.append({"role": "assistant", "content": response})

    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        
class ChatHistory:
    def __init__(self, system_prompt: str = None):
        self.system_prompt = system_prompt
        self.messages: List[BaseMessage] = []
        if system_prompt:
            self.messages.append(SystemMessage(content=system_prompt))
    
    async def add_message(self, content: str, is_bot: bool = False, author_name: str = None):
        if is_bot:
            self.messages.append(AIMessage(content=content))
        else:
            prefix = f"{author_name}: " if author_name else ""
            self.messages.append(HumanMessage(content=f"{prefix}{content}"))
    
    async def get_recent_history(self, limit: int = 10) -> List[BaseMessage]:
        start_idx = max(len(self.messages) - limit, 0)
        return self.messages[start_idx:]
    
    def clear_history(self):
        system_message = None
        if self.messages and isinstance(self.messages[0], SystemMessage):
            system_message = self.messages[0]
        self.messages.clear()
        if system_message:
            self.messages.append(system_message)
            
def init_session_state():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–"""
    MAX_MEMORY_LIMIT = 10
    #ä¿å­˜æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
    if "image_captioner" not in st.session_state:
        st.session_state.image_captioner = load_caption_model()
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    if 'memory' not in st.session_state or st.session_state.memory is None:
        st.session_state.memory = ConversationBufferMemory()
    if 'llm' not in st.session_state:
        st.session_state.llm = LLM.init_ollama()
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = ChatHistory(
            system_prompt='ã‚ãªãŸã¯çŸ¥è­˜è±Šå¯Œãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä¼šè©±ã‚’è‰¯ãç†è§£ã—ã€é©åˆ‡ãªè¿”ç­”ã‚’è¡Œã„ã¾ã™ã€‚'
        )
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä¸Šé™ã®ãƒã‚§ãƒƒã‚¯ã¨å¤ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‰Šé™¤
    if len(st.session_state.memory.chat_memory.messages) > MAX_MEMORY_LIMIT:
        st.session_state.memory.chat_memory.messages = st.session_state.memory.chat_memory.messages[-MAX_MEMORY_LIMIT:]
        
# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã¨ã—ã¦ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–
@st.cache_resource
def load_caption_model():
    # åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒã‚¤ã‚¹ã‚’å‹•çš„ã«åˆ¤å®š
    device = 0 if torch.cuda.is_available() else -1
    caption_model = pipeline(
        "image-to-text",
        model="Salesforce/blip-image-captioning-base",
        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
        device=device,
        max_new_tokens = 100
    )
    return caption_model

# ç”»åƒã‚’ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³åŒ–ã™ã‚‹é–¢æ•°
def generate_image_caption(image_file):
    try:
        # ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«ã®å–å¾—
        caption_model = st.session_state.image_captioner
        
        # ç”»åƒã‚’PILã§é–‹ã
        image = Image.open(image_file)
        
        # ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ç”Ÿæˆ
        captions = caption_model(image)
        
        # ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã®å–å¾—ï¼ˆé€šå¸¸ã¯æœ€åˆã®çµæœã‚’ä½¿ç”¨ï¼‰
        caption = captions[0]['generated_text'] if captions else "ç”»åƒã®èª¬æ˜ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
        
        return caption
    except Exception as e:
        return f"Error generating caption: {str(e)}"

# URLã‚’æ¤œå‡ºã™ã‚‹é–¢æ•°
def extract_urls(text):
    url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'
    return re.findall(url_pattern, text)

# Webãƒšãƒ¼ã‚¸ã®å†…å®¹ã‚’å–å¾—ã™ã‚‹é–¢æ•°
def get_webpage_content(url):
    try:
        response = requests.get(url, timeout=10)
        soup = BeautifulSoup(response.text, 'html.parser')
        for script in soup(["script", "style"]):
            script.decompose()
        text = soup.get_text()
        lines = (line.strip() for line in text.splitlines())
        chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
        text = ' '.join(chunk for chunk in chunks if chunk)
        return text[:5000]
    except Exception as e:
        return f"Error fetching webpage: {str(e)}"

# æ¤œç´¢ã‚¯ã‚¨ãƒªç”Ÿæˆã®ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
QUERY_PROMPT = """
ã‚ãªãŸã¯ä¸ãˆã‚‰ã‚ŒãŸè³ªå•ã«å¯¾ã—ã¦ã€ä»¥ä¸‹ã®3ã¤ã®åˆ¤æ–­ã‚’è¡Œã†ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ï¼š
1. æœ€æ–°ã®æƒ…å ±ãŒå¿…è¦ã‹ã©ã†ã‹
2. URLãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ã©ã†ã‹
3. é€šå¸¸ã®ä¼šè©±ã§å¯¾å¿œå¯èƒ½ã‹ã©ã†ã‹

è³ªå•: {question}

ä»¥ä¸‹ã®å½¢å¼ã§å¿œç­”ã—ã¦ãã ã•ã„ï¼š
NEEDS_SEARCH: [true/false] - æœ€æ–°ã®æƒ…å ±ãŒå¿…è¦ãªå ´åˆã¯true
HAS_URL: [true/false] - URLãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯true
SEARCH_QUERY: [æ¤œç´¢ã‚¯ã‚¨ãƒª] - NEEDS_SEARCHãŒtrueã®å ´åˆã®ã¿å¿…è¦ãªæ¤œç´¢ã‚¯ã‚¨ãƒªã‚’æ›¸ã„ã¦ãã ã•ã„
"""

QUESTION_PROMPT = """
ã‚ãªãŸã¯ä¸ãˆã‚‰ã‚ŒãŸæ–‡ç« ã«å¯¾ã—ã¦ã€ä»¥ä¸‹ã®åˆ¤æ–­ã‚’è¡Œã†ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ï¼š
1. æœ€å¾Œã«å•ã„ã‹ã‘ã¦ã„ã‚‹æ–‡ç« ã¯ã©ã‚Œã‹

æ–‡ç« : {questionprompt}

ä»¥ä¸‹ã®å½¢å¼ã§å¿œç­”ã—ã¦ãã ã•ã„ï¼š
NEEDS_QUESTION: [true/false] -å•ã„ã‹ã‘ã‚‰ã‚Œã¦ã„ã‚‹å ´åˆã¯true
QUESTION_QUERY: [ã‚¯ã‚¨ãƒª] - æœ€å¾Œã®è‹±èªã®å•ã„ã‹ã‘ã®æ–‡ç« ã‚’æŠœãå‡ºã—ã¦æ›¸ã„ã¦ãã ã•ã„
"""

def create_sidebar():
    with st.sidebar:
        st.header("About")
        st.markdown("""
        ãƒ» ã“ã‚“ã«ã¡ã¯ï¼ã“ã®ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã¯ã€ã•ã¾ã–ã¾ãªæ©Ÿèƒ½ã‚’å‚™ãˆã¦ã„ã¾ã™ã€‚  
        ãƒ» ã©ã‚“ãªã“ã¨ã§ã‚‚æ°—è»½ã«è©±ã—ã‹ã‘ã¦ãã ã•ã„ã­ğŸ˜Š  
        ãƒ» è‹±ä¼šè©±ã‚’ç·´ç¿’ã—ãŸã„æ™‚ã¯ã€ç”»åƒã‚’é€ä¿¡ã—ã¦ãã ã•ã„ï¼ğŸ“¸
        ã©ã‚“ãªè³ªå•ã§ã‚‚ãŠæ°—è»½ã«ã©ã†ãï¼ğŸ—£ï¸
        """, unsafe_allow_html=True)
            
        
        if st.button("ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¯ãƒªã‚¢"):
            st.session_state.chat_history.clear_history()
            st.session_state.messages = []
            MAX_MEMORY_LIMIT = 0
            st.session_state.memory.chat_memory.messages = st.session_state.memory.chat_memory.messages[-MAX_MEMORY_LIMIT:]
            st.session_state.memory = ConversationBufferMemory()

        # ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ã‚’ä¸‹ã«é…ç½®
        st.session_state.uploaded_file = st.file_uploader("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["png", "jpg", "jpeg"])

def render():
    st.title("ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ¼ãƒ‰ / Chat Mode")
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    init_session_state()
    create_sidebar()

    # DuckDuckGoæ¤œç´¢ã®åˆæœŸåŒ–
    st.session_state.search = DuckDuckGoSearchAPIWrapper(
        backend="api",
        max_results=5,
        region="jp-jp",
        safesearch="off",
        source="text",
        time="w"
    )
    st.session_state.image_flag = False
    # è³ªå•åˆ†æã®ãŸã‚ã®ãƒã‚§ãƒ¼ãƒ³
    query_prompt = PromptTemplate(template=QUERY_PROMPT, input_variables=["question"])
    query_chain = query_prompt | st.session_state.llm

    question_prompt = PromptTemplate(template=QUESTION_PROMPT, input_variables=["questionprompt"])
    question_chain = question_prompt | st.session_state.llm
    
    # Initialize chat history
    # if "chat_history" not in st.session_state:
    #     st.session_state.chat_history = []
    
    # Display chat history
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.write(message["content"])

    if st.session_state.uploaded_file:
        if 'previous_uploaded_file' not in st.session_state:
            st.session_state['previous_uploaded_file'] = None

        # æ–°ã—ã„ç”»åƒãŒå‰å›ã¨ç•°ãªã‚‹ã‹ã‚’åˆ¤å®š
        if st.session_state['previous_uploaded_file'] is None or st.session_state.uploaded_file != st.session_state['previous_uploaded_file']:
            #st.info("æ–°ã—ã„ç”»åƒãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸ")
            st.session_state.image_flag = True
            with st.chat_message("user"):
                st.image(st.session_state.uploaded_file)
                st.session_state['previous_uploaded_file'] = st.session_state.uploaded_file
            asyncio.run(handle_query(None, query_chain,question_chain, st.session_state.search, extract_urls, get_webpage_content, st.session_state.chat_history,st.session_state.uploaded_file,st.session_state.image_flag))
            #st.info("åŒã˜ç”»åƒã§è‹±ä¼šè©±ã‚’è¡Œã„ã¾ã™") 
    
    # Chat input
    if prompt := st.chat_input("è©±ã—ã‹ã‘ã¦ã¿ã‚ˆã†ï¼å·¦ã«ãƒ¡ãƒ‹ãƒ¥ãƒ¼ãŒã‚ã‚‹ã‚ˆ"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            if st.session_state.uploaded_file:
                if 'previous_uploaded_file' not in st.session_state:
                    st.session_state['previous_uploaded_file'] = None

                # æ–°ã—ã„ç”»åƒãŒå‰å›ã¨ç•°ãªã‚‹ã‹ã‚’åˆ¤å®š
                if st.session_state['previous_uploaded_file'] is None or st.session_state.uploaded_file != st.session_state['previous_uploaded_file']:
                    #st.info("æ–°ã—ã„ç”»åƒãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸ")
                    st.session_state.image_flag = True
                    st.image(st.session_state.uploaded_file)
                    st.session_state['previous_uploaded_file'] = st.session_state.uploaded_file
                else:
                    image_flag = None
                    st.image(st.session_state.uploaded_file)
                    st.info("åŒã˜ç”»åƒãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã™")       
            st.markdown(prompt)
        asyncio.run(handle_query(prompt, query_chain,question_chain, st.session_state.search, extract_urls, get_webpage_content, st.session_state.chat_history,st.session_state.uploaded_file,st.session_state.image_flag))
        st.session_state.image_flag = None