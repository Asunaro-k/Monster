import streamlit as st
from langchain.schema import HumanMessage, SystemMessage, AIMessage, BaseMessage
import mysql.connector
from mysql.connector import Error
import json
import hashlib
import os
import pandas as pd
import plotly.graph_objects as go
from decimal import Decimal, ROUND_HALF_UP
import plotly.graph_objects as go
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain, LLMChain
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.utilities import DuckDuckGoSearchAPIWrapper
from langchain.prompts import PromptTemplate
import requests
from bs4 import BeautifulSoup
import re
import asyncio
from PIL import Image
import torch
from typing import List
from transformers import pipeline
from duckduckgo_search import DDGS
from requests.exceptions import HTTPError
from langchain_ollama import ChatOllama

st.set_page_config(
    page_title="English Learning App",
    page_icon="ğŸ“š",
    layout="centered"
)

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã¨ã—ã¦ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–
@st.cache_resource
def load_caption_model():
    # åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒã‚¤ã‚¹ã‚’å‹•çš„ã«åˆ¤å®š
    device = 0 if torch.cuda.is_available() else -1
    caption_model = pipeline(
        "image-to-text",
        model="Salesforce/blip-image-captioning-base",
        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
        device=device,
        max_new_tokens = 100
    )
    return caption_model

# ç”»åƒã‚’ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³åŒ–ã™ã‚‹é–¢æ•°
def generate_image_caption(image_file):
    try:
        # ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«ã®å–å¾—
        caption_model = st.session_state.image_captioner
        
        # ç”»åƒã‚’PILã§é–‹ã
        image = Image.open(image_file)
        
        # ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ç”Ÿæˆ
        captions = caption_model(image)
        
        # ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã®å–å¾—ï¼ˆé€šå¸¸ã¯æœ€åˆã®çµæœã‚’ä½¿ç”¨ï¼‰
        caption = captions[0]['generated_text'] if captions else "ç”»åƒã®èª¬æ˜ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
        
        return caption
    except Exception as e:
        return f"Error generating caption: {str(e)}"

# URLã‚’æ¤œå‡ºã™ã‚‹é–¢æ•°
def extract_urls(text):
    url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'
    return re.findall(url_pattern, text)

# Webãƒšãƒ¼ã‚¸ã®å†…å®¹ã‚’å–å¾—ã™ã‚‹é–¢æ•°
def get_webpage_content(url):
    try:
        response = requests.get(url, timeout=10)
        soup = BeautifulSoup(response.text, 'html.parser')
        for script in soup(["script", "style"]):
            script.decompose()
        text = soup.get_text()
        lines = (line.strip() for line in text.splitlines())
        chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
        text = ' '.join(chunk for chunk in chunks if chunk)
        return text[:5000]
    except Exception as e:
        return f"Error fetching webpage: {str(e)}"

# æ¤œç´¢ã‚¯ã‚¨ãƒªç”Ÿæˆã®ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
QUERY_PROMPT = """
ã‚ãªãŸã¯ä¸ãˆã‚‰ã‚ŒãŸè³ªå•ã«å¯¾ã—ã¦ã€ä»¥ä¸‹ã®3ã¤ã®åˆ¤æ–­ã‚’è¡Œã†ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ï¼š
1. æœ€æ–°ã®æƒ…å ±ãŒå¿…è¦ã‹ã©ã†ã‹
2. URLãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ã©ã†ã‹
3. é€šå¸¸ã®ä¼šè©±ã§å¯¾å¿œå¯èƒ½ã‹ã©ã†ã‹

è³ªå•: {question}

ä»¥ä¸‹ã®å½¢å¼ã§å¿œç­”ã—ã¦ãã ã•ã„ï¼š
NEEDS_SEARCH: [true/false] - æœ€æ–°ã®æƒ…å ±ãŒå¿…è¦ãªå ´åˆã¯true
HAS_URL: [true/false] - URLãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯true
SEARCH_QUERY: [æ¤œç´¢ã‚¯ã‚¨ãƒª] - NEEDS_SEARCHãŒtrueã®å ´åˆã®ã¿å¿…è¦ãªæ¤œç´¢ã‚¯ã‚¨ãƒªã‚’æ›¸ã„ã¦ãã ã•ã„
"""

QUESTION_PROMPT = """
ã‚ãªãŸã¯ä¸ãˆã‚‰ã‚ŒãŸæ–‡ç« ã«å¯¾ã—ã¦ã€ä»¥ä¸‹ã®åˆ¤æ–­ã‚’è¡Œã†ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ï¼š
1. æœ€å¾Œã«å•ã„ã‹ã‘ã¦ã„ã‚‹æ–‡ç« ã¯ã©ã‚Œã‹

æ–‡ç« : {questionprompt}

ä»¥ä¸‹ã®å½¢å¼ã§å¿œç­”ã—ã¦ãã ã•ã„ï¼š
NEEDS_QUESTION: [true/false] -å•ã„ã‹ã‘ã‚‰ã‚Œã¦ã„ã‚‹å ´åˆã¯true
QUESTION_QUERY: [ã‚¯ã‚¨ãƒª] - æœ€å¾Œã®è‹±èªã®å•ã„ã‹ã‘ã®æ–‡ç« ã‚’æŠœãå‡ºã—ã¦æ›¸ã„ã¦ãã ã•ã„
"""

def init_session_state():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–"""
    MAX_MEMORY_LIMIT = 10
    #ä¿å­˜æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
    if "image_captioner" not in st.session_state:
        st.session_state.image_captioner = load_caption_model()
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    if 'memory' not in st.session_state:
        st.session_state.memory = ConversationBufferMemory()
    if 'llm' not in st.session_state:
        st.session_state.llm = init_ollama()
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = ChatHistory(
            system_prompt='ã‚ãªãŸã¯çŸ¥è­˜è±Šå¯Œãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä¼šè©±ã‚’è‰¯ãç†è§£ã—ã€é©åˆ‡ãªè¿”ç­”ã‚’è¡Œã„ã¾ã™ã€‚'
        )
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä¸Šé™ã®ãƒã‚§ãƒƒã‚¯ã¨å¤ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‰Šé™¤
    if len(st.session_state.memory.chat_memory.messages) > MAX_MEMORY_LIMIT:
        st.session_state.memory.chat_memory.messages = st.session_state.memory.chat_memory.messages[-MAX_MEMORY_LIMIT:]
        
    

class ChatHistory:
    def __init__(self, system_prompt: str = None):
        self.system_prompt = system_prompt
        self.messages: List[BaseMessage] = []
        if system_prompt:
            self.messages.append(SystemMessage(content=system_prompt))
    
    async def add_message(self, content: str, is_bot: bool = False, author_name: str = None):
        if is_bot:
            self.messages.append(AIMessage(content=content))
        else:
            prefix = f"{author_name}: " if author_name else ""
            self.messages.append(HumanMessage(content=f"{prefix}{content}"))
    
    async def get_recent_history(self, limit: int = 10) -> List[BaseMessage]:
        start_idx = max(len(self.messages) - limit, 0)
        return self.messages[start_idx:]
    
    def clear_history(self):
        system_message = None
        if self.messages and isinstance(self.messages[0], SystemMessage):
            system_message = self.messages[0]
        self.messages.clear()
        if system_message:
            self.messages.append(system_message)


async def handle_query(prompt, query_chain,question_chain, search, extract_urls, get_webpage_content, chat_history, image_file=None, imageflag=None):
    try:
        chain = ConversationChain(
                    llm=st.session_state.llm,
                    memory=st.session_state.memory,
                    verbose=True
                )
        # ç”»åƒãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹å ´åˆ
        if image_file is not None:
            #comment_prompt = f"ã“ã®ç”»åƒã«é–¢ã™ã‚‹è³ªå•/ã‚³ãƒ¡ãƒ³ãƒˆï¼š{prompt}" if prompt is not None else ""
            # å‰å›ã®ç”»åƒã¨ç•°ãªã‚‹å ´åˆã¯ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆã—ã¦ä¼šè©±
            if imageflag:
                # ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ç”Ÿæˆ
                with st.spinner('ç”»åƒã‚’è§£æä¸­...'):
                    caption = generate_image_caption(image_file)
                st.info(f"ç”»åƒã®èª¬æ˜: {caption}")
                
                prompt_with_image = f"""ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åŸºã¥ã„ãŸç°¡å˜ãªè‹±ä¼šè©±ã‚’ã‚ãªãŸã¨ã—ãŸã„ã§ã™ã€‚
                ä»¥ä¸‹ã«ä¾‹ã‚’å¼µã‚Šã¾ã™ã€‚ä¾‹ãªã®ã§çŒ«ãªã©ã®å†…å®¹ã¯ç„¡è¦–ã—ã¦ãã ã•ã„ã€‚\n
                A: Look at the cat! It's sitting on the floor in front of the kitchen. (è¦‹ã¦ï¼çŒ«ãŒã‚­ãƒƒãƒãƒ³ã®å‰ã®åºŠã«åº§ã£ã¦ã‚‹ã‚ˆã€‚)\n
                B: Yeah, it looks so relaxed! (ã‚ã‚ã€ã¾ã£ãŸã‚Šã—ã¦ã‚‹ã­ï¼)\n
                A: I know, right? Maybe it's waiting for food. (ãã†ã ã‚ˆã­ï¼Ÿã‚‚ã—ã‹ã—ãŸã‚‰ã”é£¯ãŒé£Ÿã¹ãŸã„ã‹ã‚‰å¾…ã£ã¦ã‚‹ã®ã‹ãªã€‚)\n
                B: Do you think the cat is hungry? (çŒ«ã¯ãŠãªã‹ã™ã„ã¦ã‚‹ã‹ãªï¼Ÿ)\n
                A: Hmm, maybe. Cats love food! (ãˆãƒ¼ã€ã‚‚ã—ã‹ã—ãŸã‚‰ã€‚çŒ«ã¯é£Ÿã¹ç‰©ãŒå¤§å¥½ããªã‚“ã ã‚ˆï¼)\n\n
                Question: What do you think the cat would say if it could talk? (çŒ«ãŒè©±ã™ã“ã¨ãŒã§ããŸã‚‰ä½•ã¨è¨€ã†ã‹ãªï¼Ÿ)\n
                
                ä¸Šè¨˜ã®ã‚ˆã†ã«ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦ä½•å›ã‹æ—¥æœ¬èªè¨³ã‚’ã¤ã‘ãŸè‹±ä¼šè©±ã‚’ã—ãŸã†ãˆã§ã€æœ€å¾Œã«æ—¥æœ¬èªè¨³ã‚’ã¤ã‘ãŸè‹±èªã§ç§ã«ä½•ã‹è³ªå•ã‹å•ã„ã‹ã‘ã‚’ã—ã¦ãã ã•ã„ã€‚ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼š
                {caption}

                """
                
                #response = await st.session_state.llm.apredict(prompt_with_image)
                reply = await chain.ainvoke(prompt_with_image)
                response = reply['response']
                await chat_history.add_message(prompt_with_image, is_bot=False)
                await chat_history.add_message(response, is_bot=True)
                st.session_state['questionprompt'] = response
                st.session_state['previous_uploaded_file'] = image_file
                analysis = await question_chain.ainvoke(st.session_state.get('questionprompt', ''))
                content = analysis.content if hasattr(analysis, 'content') else str(analysis)
                st.session_state['needs_question'] = "NEEDS_QUESTION: true" in content
                if st.session_state['needs_question']:
                    question_query = re.search(r'QUESTION_QUERY: (.*)', content)
                    st.session_state['question_query'] = question_query.group(1)
                    st.session_state['needs_question'] = False
                
            else:
                st.markdown("Question")
                st.markdown(f"{st.session_state['question_query']}")
                # åŒã˜ç”»åƒã®å ´åˆã¯è‹±ä¼šè©±ã®æ­£èª¤åˆ¤å®šã‚µãƒãƒ¼ãƒˆ
                prompt_with_support = f"""
                
                ã‚ãªãŸã®ç›®æ¨™ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ¥½ã—ãè‹±ä¼šè©±ã‚’ç·´ç¿’ã—ã€ä¸Šé”ã§ãã‚‹ã‚ˆã†ã«ã‚µãƒãƒ¼ãƒˆã™ã‚‹ã“ã¨ã§ã™ã€‚
                æ¬¡ã®æ–‡ç« ã®è‹±èªã®æ­£ã—ã•ã‚’æ—¥æœ¬èªã§è©•ä¾¡ã—ã€ã‚ã£ã¦ã„ã‚‹å ´åˆã¯è¤’ã‚ã¦ãã ã•ã„ã€‚
                è‹±èªã§ã¯ãªã„å ´åˆã‚„é–“é•ã£ã¦ã„ã‚‹å ´åˆã¯ä¿®æ­£ã‚’ææ¡ˆã—ã€ä¿®æ­£ã—ãŸè‹±èªã‚’è©±ã—ã¦ãã ã•ã„ã€‚
                ã¾ãŸãã®å¾Œã‚‚ä¼šè©±ã‚’ç¶šã‘ã¾ã™ã€‚\n
                ä»¥ä¸‹ã«ä¾‹ã‚’å¼µã‚Šã¾ã™ã€‚ä¾‹ãªã®ã§å²©ã®å´–ãªã©ã®å†…å®¹ã¯ç„¡è¦–ã—ã¦ãã ã•ã„ã€‚\n
                Question: What do you think is the most beautiful rocky cliff with a body of water in the world?\n
                ä¸Šè¨˜ã®ã‚ˆã†ã«æ—¥æœ¬èªè¨³ã‚’ã¤ã‘ãŸè‹±èªã§ç§ã«ä½•ã‹è³ªå•ã‹å•ã„ã‹ã‘ã‚’ã—ã¦ãã ã•ã„ã€‚
                å‰å›ã®å‡ºåŠ›ã§æ¬¡ã®ã‚ˆã†ãªä¼šè©±ã‚’è¡Œã„ã¾ã—ãŸã€‚ï¼š{st.session_state.get('questionprompt', '')}\n
                è³ªå•ã®å›ç­”: {prompt}"""
                
                
                
                #response = await st.session_state.llm.apredict(prompt_with_support)
                reply = await chain.ainvoke(prompt_with_support)
                response = reply['response']
                #response = await chain.ainvoke(prompt_with_support)
                st.session_state['questionprompt'] = response
                await chat_history.add_message(prompt_with_support, is_bot=False)
                await chat_history.add_message(response, is_bot=True)
                analysis = await question_chain.ainvoke(response)
                content = analysis.content if hasattr(analysis, 'content') else str(analysis)
                st.session_state['needs_question'] = "NEEDS_QUESTION: true" in content
                if st.session_state['needs_question']:
                    question_query = re.search(r'QUESTION_QUERY: (.*)', content)
                    st.session_state['question_query'] = question_query.group(1)
                    st.session_state['needs_question'] = False
        else:
            # é€šå¸¸ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ã®å‡¦ç†
            #recent_history = await chat_history.get_recent_history()
            analysis = await query_chain.ainvoke(prompt)
            content = analysis.content if hasattr(analysis, 'content') else str(analysis)
            needs_search = "NEEDS_SEARCH: true" in content
            has_url = "HAS_URL: true" in content

            if has_url:
                urls = extract_urls(prompt)
                if urls:
                    webpage_content = get_webpage_content(urls[0])
                    prompt_with_content = f"ä»¥ä¸‹ã®Webãƒšãƒ¼ã‚¸ã®å†…å®¹ã«åŸºã¥ã„ã¦é©åˆ‡ãªè¿”ç­”ã‚’è€ƒãˆã¦ãã ã•ã„ã€‚åºƒå‘Šã‚„é–¢é€£è¨˜äº‹ãªã©ã«æ°—ã‚’å–ã‚‰ã‚Œãªã„ã§ãã ã•ã„ã€‚\n\nWebãƒšãƒ¼ã‚¸å†…å®¹: {webpage_content}\n\nè³ªå•: {prompt}"
                    #response = await st.session_state.llm.apredict(prompt_with_content)
                    #response = await chain.ainvoke(prompt_with_content)
                    reply = await chain.ainvoke(prompt_with_content)
                    response = reply['response']
            elif needs_search:
                st.markdown("""DuckDuckGoã§æ¤œç´¢ä¸­...""")
                search_query = re.search(r'SEARCH_QUERY: (.*)', content)
                if search_query:
                    search_results = search.run(search_query.group(1))
                    prompt_with_search = f"""ä»¥ä¸‹ã®æ¤œç´¢çµæœã®å†…å®¹ã«åŸºã¥ã„ã¦é©åˆ‡ãªè¿”ç­”ã‚’è€ƒãˆã¦ãã ã•ã„ã€‚åºƒå‘Šã‚„é–¢é€£è¨˜äº‹ãªã©ã«æ°—ã‚’å–ã‚‰ã‚Œãªã„ã§ãã ã•ã„ã€‚
                    ã§ãã‚‹ã ã‘æœ€æ–°ã®æƒ…å ±ã‚’å«ã‚ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚

                    æ¤œç´¢çµæœ: {search_results}

                    è³ªå•: {prompt}
                    """
                    
                    #response = await st.session_state.llm.apredict(prompt_with_search)
                    reply = await chain.ainvoke(prompt_with_search)
                    response = reply['response']
                else:
                    response = "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€‚æ¤œç´¢ã‚¯ã‚¨ãƒªã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚"
            else:
                #st.markdown(st.session_state.memory)
                reply = await chain.ainvoke(prompt)
                response = reply['response']

        # å¿œç­”ã®è¡¨ç¤º
        with st.chat_message("assistant"):
            st.markdown(response)
        st.session_state.messages.append({"role": "assistant", "content": response})

    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")


def init_ollama():
    llm = ChatOllama(
        base_url="http://host.docker.internal:11434/",
        #llama3.1:8b
        #llama3.2:latest
        #7shi/tanuki-dpo-v1.0:latest
        model="gemma2:9b",
        temperature=0.7
    )
    return llm

# Database configuration
DB_CONFIG = {
    'host': os.environ["DB_HOST"],
    'user': os.environ["DB_USER"],
    'password': os.environ["DB_PASSWORD"],
    'database': os.environ["DB_NAME"]
}

# Database initialization
def init_db():
    try:
        conn = mysql.connector.connect(**DB_CONFIG)
        cursor = conn.cursor()
        
        # Create users table
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS users (
                id INT AUTO_INCREMENT PRIMARY KEY,
                username VARCHAR(255) UNIQUE NOT NULL,
                password_hash VARCHAR(255) NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # Create progress table
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS user_progress (
                id INT AUTO_INCREMENT PRIMARY KEY,
                user_id INT,
                score INT DEFAULT 0,
                total_correct INT DEFAULT 0,
                total_attempts INT DEFAULT 0,
                last_session TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (user_id) REFERENCES users(id)
            )
        ''')
        
        # Create history table
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS learning_history (
                id INT AUTO_INCREMENT PRIMARY KEY,
                user_id INT,
                japanese_text TEXT,
                english_text TEXT,
                is_correct BOOLEAN,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (user_id) REFERENCES users(id)
            )
        ''')
        
        conn.commit()
    except Error as e:
        st.error(f"Database error: {e}")
    finally:
        if conn.is_connected():
            cursor.close()
            conn.close()


def get_learning_history_data(user_id):
    try:
        conn = mysql.connector.connect(**DB_CONFIG)
        cursor = conn.cursor(dictionary=True)
        
        # éå»30æ—¥é–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        cursor.execute("""
            SELECT 
                DATE(created_at) as date,
                COUNT(*) as total_attempts,
                SUM(CASE WHEN is_correct THEN 1 ELSE 0 END) as correct_answers,
                HOUR(created_at) as hour
            FROM learning_history
            WHERE user_id = %s
                AND created_at >= DATE_SUB(NOW(), INTERVAL 30 DAY)
            GROUP BY DATE(created_at), HOUR(created_at)
            ORDER BY date, hour
        """, (user_id,))
        
        return cursor.fetchall()
    except Error as e:
        st.error(f"Error getting history data: {e}")
        return []
    finally:
        if conn.is_connected():
            cursor.close()
            conn.close()

def create_performance_graphs():
    history_data = get_learning_history_data(st.session_state.user['id'])
    
    if not history_data:
        st.info("å­¦ç¿’å±¥æ­´ãŒã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚å•é¡Œã‚’è§£ã„ã¦çµ±è¨ˆã‚’ä½œæˆã—ã¾ã—ã‚‡ã†ï¼")
        return
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’Pandas DataFrameã«å¤‰æ›
    df = pd.DataFrame(history_data)
    
    # æ—¥åˆ¥ã®æ­£è§£ç‡ã®è¨ˆç®—
    daily_stats = df.groupby('date').agg({
        'total_attempts': 'sum',
        'correct_answers': 'sum'
    }).reset_index()
    daily_stats['accuracy'] = (daily_stats['correct_answers'] / daily_stats['total_attempts'] * 100).round(1)
    
    # æ™‚é–“å¸¯åˆ¥ã®å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³
    hourly_stats = df.groupby('hour').agg({
        'total_attempts': 'sum'
    }).reset_index()
    
    # æ—¥åˆ¥æ­£è§£ç‡ã®ã‚°ãƒ©ãƒ•
    fig1 = go.Figure()
    fig1.add_trace(go.Scatter(
        x=daily_stats['date'],
        y=daily_stats['accuracy'],
        mode='lines+markers',
        name='æ­£è§£ç‡',
        line=dict(color='#2E86C1'),
        marker=dict(size=8)
    ))
    fig1.update_layout(
        title='æ—¥åˆ¥æ­£è§£ç‡ã®æ¨ç§»',
        xaxis_title='æ—¥ä»˜',
        yaxis_title='æ­£è§£ç‡ (%)',
        yaxis_range=[0, 100],
        height=400,
        margin=dict(l=20, r=20, t=40, b=20),
        paper_bgcolor='rgba(0,0,0,0)',
        plot_bgcolor='rgba(0,0,0,0)',
    )
    
    # æ™‚é–“å¸¯åˆ¥å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã‚°ãƒ©ãƒ•
    fig2 = go.Figure()
    fig2.add_trace(go.Bar(
        x=hourly_stats['hour'],
        y=hourly_stats['total_attempts'],
        marker_color='#2E86C1'
    ))
    fig2.update_layout(
        title='æ™‚é–“å¸¯åˆ¥å­¦ç¿’å›æ•°',
        xaxis_title='æ™‚é–“',
        yaxis_title='å­¦ç¿’å›æ•°',
        height=400,
        margin=dict(l=20, r=20, t=40, b=20),
        paper_bgcolor='rgba(0,0,0,0)',
        plot_bgcolor='rgba(0,0,0,0)',
    )
    
    # çµ±è¨ˆã‚µãƒãƒªãƒ¼
    total_answers = daily_stats['total_attempts'].sum()
    total_correct = daily_stats['correct_answers'].sum()
    #average_accuracy = (total_correct / total_answers * 100).round(1) if total_answers > 0 else 0
    # ç²¾åº¦è¨ˆç®—
    if total_answers > 0:
        total_answers = int(total_answers)  # numpy.int64ã‚’intã«å¤‰æ›
        total_correct = int(total_correct)  # numpy.int64ã‚’intã«å¤‰æ›
        
        accuracy = Decimal(total_correct) / Decimal(total_answers) * Decimal(100)
        average_accuracy = accuracy.quantize(Decimal('0.1'), rounding=ROUND_HALF_UP)  # å°æ•°ç¬¬1ä½ã«ä¸¸ã‚ã‚‹
    else:
        average_accuracy = Decimal(0)
    
    # UIè¡¨ç¤º
    st.write("## å­¦ç¿’çµ±è¨ˆ")
    
    # ã‚µãƒãƒªãƒ¼çµ±è¨ˆ
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ç·å›ç­”æ•°", f"{total_answers:,}")
    with col2:
        st.metric("ç·æ­£è§£æ•°", f"{total_correct:,}")
    with col3:
        st.metric("å¹³å‡æ­£è§£ç‡", f"{average_accuracy}%")
    
    # ã‚°ãƒ©ãƒ•ã®è¡¨ç¤º
    st.plotly_chart(fig1, use_container_width=True)
    st.plotly_chart(fig2, use_container_width=True)
    
    # è©³ç´°ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤ºï¼ˆå±•é–‹å¯èƒ½ï¼‰
    with st.expander("è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º"):
        st.dataframe(
            daily_stats.rename(columns={
                'date': 'æ—¥ä»˜',
                'total_attempts': 'ç·å›ç­”æ•°',
                'correct_answers': 'æ­£è§£æ•°',
                'accuracy': 'æ­£è§£ç‡(%)'
            }),
            hide_index=True
        )
        
def search_images(query, num_results=5):
    try:
        ddgs = DDGS()
        results = ddgs.images(query)
        return results[:num_results]  # æ¤œç´¢çµæœã‚’æŒ‡å®šã•ã‚ŒãŸæ•°ã ã‘è¿”ã™
    except HTTPError as e:
        # RatelimitException ã‚‚ã—ãã¯ä»–ã®HTTPã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆ
        if e.response.status_code == 429:  # 429ã¯ãƒ¬ãƒ¼ãƒˆãƒªãƒŸãƒƒãƒˆã‚¨ãƒ©ãƒ¼
            st.warning("Too many requests. Please wait before trying again.")
        else:
            st.error(f"Error occurred: {e}")
        return []

def setting_confi():
    tmp = st.session_state.generate_toggle
    toggle = st.toggle("ç”»åƒç”Ÿæˆã‚’æœ‰åŠ¹ã«ã™ã‚‹")
    if tmp != toggle:
        st.session_state.generate_toggle = toggle
    st.write(st.session_state.generate_toggle)
    st.rerun()
        
# User authentication functions
def hash_password(password):
    return hashlib.sha256(password.encode()).hexdigest()

def create_user(username, password):
    try:
        conn = mysql.connector.connect(**DB_CONFIG)
        cursor = conn.cursor()
        
        password_hash = hash_password(password)
        cursor.execute(
            "INSERT INTO users (username, password_hash) VALUES (%s, %s)",
            (username, password_hash)
        )
        
        user_id = cursor.lastrowid
        cursor.execute(
            "INSERT INTO user_progress (user_id) VALUES (%s)",
            (user_id,)
        )
        
        conn.commit()
        return True
    except Error as e:
        st.error(f"Error creating user: {e}")
        return False
    finally:
        if conn.is_connected():
            cursor.close()
            conn.close()

def verify_user(username, password):
    try:
        conn = mysql.connector.connect(**DB_CONFIG)
        cursor = conn.cursor(dictionary=True)
        
        password_hash = hash_password(password)
        cursor.execute(
            "SELECT * FROM users WHERE username = %s AND password_hash = %s",
            (username, password_hash)
        )
        
        user = cursor.fetchone()
        return user
    except Error as e:
        st.error(f"Error verifying user: {e}")
        return None
    finally:
        if conn.is_connected():
            cursor.close()
            conn.close()

def update_user_progress(user_id, is_correct):
    try:
        conn = mysql.connector.connect(**DB_CONFIG)
        cursor = conn.cursor()
        
        cursor.execute("""
            UPDATE user_progress 
            SET total_attempts = total_attempts + 1,
                total_correct = total_correct + %s,
                score = score + %s,
                last_session = CURRENT_TIMESTAMP
            WHERE user_id = %s
        """, (1 if is_correct else 0, 1 if is_correct else -1, user_id))
        
        conn.commit()
    except Error as e:
        st.error(f"Error updating progress: {e}")
    finally:
        if conn.is_connected():
            cursor.close()
            conn.close()

def get_user_progress(user_id):
    try:
        conn = mysql.connector.connect(**DB_CONFIG)
        cursor = conn.cursor(dictionary=True)
        
        cursor.execute(
            "SELECT * FROM user_progress WHERE user_id = %s",
            (user_id,)
        )
        
        return cursor.fetchone()
    except Error as e:
        st.error(f"Error getting progress: {e}")
        return None
    finally:
        if conn.is_connected():
            cursor.close()
            conn.close()

def save_learning_history(user_id, japanese_text, english_text, is_correct):
    try:
        conn = mysql.connector.connect(**DB_CONFIG)
        cursor = conn.cursor()
        
        cursor.execute("""
            INSERT INTO learning_history 
            (user_id, japanese_text, english_text, is_correct)
            VALUES (%s, %s, %s, %s)
        """, (user_id, japanese_text, english_text, is_correct))
        
        conn.commit()
    except Error as e:
        st.error(f"Error saving history: {e}")
    finally:
        if conn.is_connected():
            cursor.close()
            conn.close()

# Login/Signup UI
def show_auth_ui():
    tab1, tab2 = st.tabs(["Login", "Sign Up"])
    
    with tab1:
        with st.form("login_form"):
            username = st.text_input("Username")
            password = st.text_input("Password", type="password")
            submit = st.form_submit_button("Login")
            
            if submit:
                user = verify_user(username, password)
                if user:
                    st.session_state.user = user
                    st.session_state.authenticated = True
                    st.success("Successfully logged in!")
                    st.rerun()
                else:
                    st.error("Invalid username or password")
    
    with tab2:
        with st.form("signup_form"):
            new_username = st.text_input("Choose Username")
            new_password = st.text_input("Choose Password", type="password")
            confirm_password = st.text_input("Confirm Password", type="password")
            submit = st.form_submit_button("Sign Up")
            
            if submit:
                if new_password != confirm_password:
                    st.error("Passwords do not match")
                elif len(new_password) < 6:
                    st.error("Password must be at least 6 characters long")
                else:
                    if create_user(new_username, new_password):
                        st.success("Account created successfully! Please log in.")
                    else:
                        st.error("Username already exists")

# Main app functions (modified to include user data)
def generate_new_sentence():
    # Ollamaã®åˆæœŸåŒ–
    chat = init_ollama()
    # LLMã«é€ä¿¡ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    # system_prompt = """Decide on one random theme and generate a simple Japanese sentence and its English translation. 
    # Return it as a JSON object with format: 
    # {"japanese": "æ—¥æœ¬èªã®æ–‡", "english": "English sentence"} 
    # Keep sentences simple and suitable for language learners."""
    system_prompt = """Please decide on a random theme and generate one English sentences and their Japanese translations for phrases commonly used in conversation and other situations.
    Return it as a JSON object in the format: 
    {"english": "English sentence", "japanese": "æ—¥æœ¬èªã®æ–‡"} 
    Keep the sentences simple and appropriate for language learners."""

    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ä½œæˆ
    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content="Generate a new sentence")
    ]

    # å¿œç­”ã®å‡¦ç†
    try:
        # Chatãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã®å¿œç­”ã‚’å–å¾—
        response = chat.invoke(messages)

        raw_content = response.content.strip()

        # ` ```json` ãƒ–ãƒ­ãƒƒã‚¯ãŒã‚ã‚‹å ´åˆ
        match = re.search(r"```json\s*(\{.*?\})\s*```", raw_content, re.DOTALL)

        if match:
            # JSONéƒ¨åˆ†ã ã‘ã‚’æŠ½å‡º
            raw_content = match.group(1)
        
        # JSONãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰
        try:
            data = json.loads(raw_content)
            #st.write("Parsed JSON:", data)
        except json.JSONDecodeError as e:
            st.error(f"JSONãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")

        # å¿…è¦ãªæ“ä½œã‚’ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå´ã§å®Ÿè¡Œ
        # æœ«å°¾ã®è‹±èªã®å¥èª­ç‚¹ã‚’å‰Šé™¤
        english_sentence = re.sub(r"[.!?]+$", "", data["english"])

        # æœ«å°¾ã®æ—¥æœ¬èªã®å¥èª­ç‚¹ã‚’å‰Šé™¤
        japanese_sentence = re.sub(r"[ã€‚ï¼ï¼Ÿ]+$", "", data["japanese"])
        

        # å˜èªã®åˆ†å‰²ã¨ã‚·ãƒ£ãƒƒãƒ•ãƒ«
        import random

        # å˜èªã‚’å°æ–‡å­—ã«ã—ã¦åˆ†å‰²
        available_words = english_sentence.lower().split()

        # ã‚·ãƒ£ãƒƒãƒ•ãƒ« (å…ƒã®ãƒªã‚¹ãƒˆã¯å¤‰æ›´ã•ã‚Œã‚‹)
        shuffled_words = available_words[:]  # ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆ
        random.shuffle(shuffled_words)

        # Streamlit ã®çŠ¶æ…‹ã«è¨­å®š
        st.session_state.current_sentence = english_sentence
        st.session_state.translation = japanese_sentence
        st.session_state.correct_words = available_words
        st.session_state.available_words = shuffled_words  # ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã•ã‚ŒãŸå˜èª
        st.session_state.selected_words = []
        # available_words = english_sentence.lower().split()
        # st.session_state.current_sentence = english_sentence
        # st.session_state.translation = japanese_sentence
        # st.session_state.correct_words = available_words
        # st.session_state.available_words = available_words
        # st.session_state.selected_words = []

        # ãƒ‡ãƒãƒƒã‚°è¡¨ç¤º
        # st.write("English Sentence:", english_sentence)
        # st.write("Japanese Sentence:", japanese_sentence)
        # st.write("Available Words:", available_words)

    except json.JSONDecodeError as e:
        st.error(f"JSONãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        st.write("ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒJSONå½¢å¼ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ¬ã‚¹ãƒãƒ³ã‚¹å†…å®¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

def create_chat_ui():
    st.session_state.image_flag = False
    st.title("è‹±èªå­¦ç¿’ãƒãƒ£ãƒƒãƒˆ")
    # è³ªå•åˆ†æã®ãŸã‚ã®ãƒã‚§ãƒ¼ãƒ³
    query_prompt = PromptTemplate(template=QUERY_PROMPT, input_variables=["question"])
    query_chain = query_prompt | st.session_state.llm

    question_prompt = PromptTemplate(template=QUESTION_PROMPT, input_variables=["questionprompt"])
    question_chain = question_prompt | st.session_state.llm
    
    # Initialize chat history
    # if "chat_history" not in st.session_state:
    #     st.session_state.chat_history = []
    
    # Display chat history
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.write(message["content"])

    if st.session_state.uploaded_file:
        if 'previous_uploaded_file' not in st.session_state:
            st.session_state['previous_uploaded_file'] = None

        # æ–°ã—ã„ç”»åƒãŒå‰å›ã¨ç•°ãªã‚‹ã‹ã‚’åˆ¤å®š
        if st.session_state['previous_uploaded_file'] is None or st.session_state.uploaded_file != st.session_state['previous_uploaded_file']:
            #st.info("æ–°ã—ã„ç”»åƒãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸ")
            st.session_state.image_flag = True
            with st.chat_message("user"):
                st.image(st.session_state.uploaded_file)
                st.session_state['previous_uploaded_file'] = st.session_state.uploaded_file
            asyncio.run(handle_query(None, query_chain,question_chain, st.session_state.search, extract_urls, get_webpage_content, st.session_state.chat_history,st.session_state.uploaded_file,st.session_state.image_flag))
            #st.info("åŒã˜ç”»åƒã§è‹±ä¼šè©±ã‚’è¡Œã„ã¾ã™") 
    
    # Chat input
    if prompt := st.chat_input("è©±ã—ã‹ã‘ã¦ã¿ã‚ˆã†ï¼å·¦ã«ãƒ¡ãƒ‹ãƒ¥ãƒ¼ãŒã‚ã‚‹ã‚ˆ"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            if st.session_state.uploaded_file:
                if 'previous_uploaded_file' not in st.session_state:
                    st.session_state['previous_uploaded_file'] = None

                # æ–°ã—ã„ç”»åƒãŒå‰å›ã¨ç•°ãªã‚‹ã‹ã‚’åˆ¤å®š
                if st.session_state['previous_uploaded_file'] is None or st.session_state.uploaded_file != st.session_state['previous_uploaded_file']:
                    #st.info("æ–°ã—ã„ç”»åƒãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸ")
                    st.session_state.image_flag = True
                    st.image(st.session_state.uploaded_file)
                    st.session_state['previous_uploaded_file'] = st.session_state.uploaded_file
                else:
                    image_flag = None
                    st.image(st.session_state.uploaded_file)
                    st.info("åŒã˜ç”»åƒãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã™")       
            st.markdown(prompt)
        asyncio.run(handle_query(prompt, query_chain,question_chain, st.session_state.search, extract_urls, get_webpage_content, st.session_state.chat_history,st.session_state.uploaded_file,st.session_state.image_flag))
        st.session_state.image_flag = None
            
def create_word_buttons(cols, available_words, selected_words, tab_key=""):
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä»˜ãã®å˜èªãƒªã‚¹ãƒˆã‚’ä½œæˆ
    word_objects = [{"id": idx, "word": word} for idx, word in enumerate(available_words)]
    
    # å„å˜èªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¯¾ã—ã¦ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
    for word_obj in word_objects:
        col_idx = word_obj["id"] % 4
        with cols[col_idx]:
            # ã“ã®å˜èªã®IDãŒã¾ã é¸æŠã•ã‚Œã¦ã„ãªã„ã‹ç¢ºèª
            if not any(selected["id"] == word_obj["id"] for selected in selected_words):
                if st.button(word_obj["word"], key=f"{tab_key}_word_{word_obj['id']}"):
                    selected_words.append(word_obj)
                    st.rerun()

def create_app_ui():
    st.title("è‹±èªå­¦ç¿’ã‚¢ãƒ—ãƒª")
    # Get user progress
    progress = get_user_progress(st.session_state.user['id'])
    # ã‚¿ãƒ–ã‚’ä½œæˆ
    tab1, tab2, tab3 = st.tabs(["å­¦ç¿’", "çµ±è¨ˆ","ç”»åƒ"])
    with tab1:
        # Display user stats
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Score", progress['score'])
        with col2:
            st.metric("Correct Answers", progress['total_correct'])
        with col3:
            accuracy = (progress['total_correct'] / progress['total_attempts'] * 100) if progress['total_attempts'] > 0 else 0
            st.metric("Accuracy", f"{accuracy:.1f}%")
            
        # if st.session_state.generate_toggle:
        #     if st.session_state.learnimage is None:
        #     # Display Japanese sentence
        #         prompt= f"{st.session_state.translation}:The image is reminiscent of this scene, illustration style, masterpiece"
        #         negative_prompt=""
        #         image = asyncio.run(generate_monster_image(prompt,negative_prompt))
        #         if image:
        #             st.session_state.learnimage = image
                    
        #     if st.session_state.learnimage:
        #             st.image(st.session_state.learnimage)
                  
        st.write("### " + st.session_state.translation)
        
        # selected_wordsã®åˆæœŸåŒ–
        if "selected_words" not in st.session_state:
            st.session_state.selected_words = []
            
        # é¸æŠã•ã‚ŒãŸå˜èªã‚’è¡¨ç¤ºï¼ˆå˜èªãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã‚’æŠ½å‡ºã—ã¦çµåˆï¼‰
        selected_text = " ".join(word_obj["word"] for word_obj in st.session_state.selected_words)
        st.text_area("Your answer:", selected_text, height=100, key="tab1_answer")
        
        # Available words as buttons
        st.write("### Available words:")
        cols = st.columns(4)
        
        # for idx, word in enumerate(st.session_state.available_words):
        #     col_idx = idx % 4
        #     with cols[col_idx]:
        #         if word not in st.session_state.selected_words:
        #             if st.button(word, key=f"word_{idx}"):
        #                 st.session_state.selected_words.append(word)
        #                 st.rerun()
        # Initialize selected_words as a list of word objects if not already done
        # ãƒœã‚¿ãƒ³ã®ä½œæˆ
        create_word_buttons(cols, st.session_state.available_words, st.session_state.selected_words, tab_key="tab1")

        # Check answer button
        if st.button("Check Answer", type="primary"):
            selected_word_list = [word_obj["word"] for word_obj in st.session_state.selected_words]
            is_correct = " ".join(selected_word_list).lower() == " ".join(st.session_state.correct_words).lower()
            #is_correct = " ".join(st.session_state.selected_words).lower() == " ".join(st.session_state.correct_words).lower()
            #st.write(st.session_state.selected_words)
            #st.write(st.session_state.correct_words)
            if is_correct:
                st.success("Correct! ğŸ‰")
                st.balloons()
            else:
                st.error("Try again!")
            
            # Update progress and save history
            update_user_progress(st.session_state.user['id'], is_correct)
            save_learning_history(
                st.session_state.user['id'],
                st.session_state.translation,
                st.session_state.current_sentence,
                is_correct
            )
            
            if is_correct:
                generate_new_sentence()
                st.session_state.Flag_serachimag = False
                st.session_state.learnimage = None
                st.rerun()

        # Control buttons
        col1, col2 = st.columns(2)
        with col1:
            if st.button("Clear"):
                st.session_state.selected_words = []
                st.rerun()
        with col2:
            if st.button("New Sentence"):
                generate_new_sentence()
                st.session_state.learnimage = None
                st.rerun()
        
        # Logout button
        # if st.sidebar.button("Logout"):
        #     st.session_state.clear()
        #     st.rerun()
    
    with tab2:
        # çµ±è¨ˆã‚°ãƒ©ãƒ•ã®è¡¨ç¤º
        create_performance_graphs()
    with tab3:
        setting_confi()

        
def create_sidebar():
    with st.sidebar:
        if st.session_state.get("authenticated"):
            st.title("ãƒ¡ãƒ‹ãƒ¥ãƒ¼ / Menu")
            
            # Mode selection
            st.write("### ãƒ¢ãƒ¼ãƒ‰é¸æŠ / Mode Selection")
            if st.button("å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ / Study Mode", 
                        type="primary" if st.session_state.get("mode", "study") == "study" else "secondary"):
                st.session_state.mode = "study"
                st.rerun()
            
            if st.button("ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ¼ãƒ‰ / Chat Mode",
                        type="primary" if st.session_state.get("mode", "study") == "chat" else "secondary"):
                st.session_state.mode = "chat"
                st.rerun()

            if st.button("è‹±ä¼šè©±ãƒ¢ãƒ¼ãƒ‰ / Speaking Talking Mode",
                        type="primary" if st.session_state.get("mode", "study") == "stt" else "secondary"):
                st.session_state.mode = "stt"
                st.rerun()

            if st.session_state.mode=="stt":
                st.session_state.levels = st.sidebar.radio(
                    "ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³",
                    ["é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ (usual)", "åˆå¿ƒè€… (Beginner)", "ä¸­ç´šè€… (Intermediate)", "ä¸Šç´šè€… (Advanced)","è‚²æˆ"],
                    index=0,
                )
                #st.session_state.levels = "é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ (usual)"
                with st.sidebar:
                    if st.button("æ–°ã—ã„å•é¡Œã‚’ç”Ÿæˆ"):
                        # å•é¡Œå†ç”Ÿæˆæ™‚ã«çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
                        st.session_state.flag = False
                        st.session_state.prompt = None
                        st.session_state.reset_audio_input = True
            
            if st.session_state.mode=="chat":
                st.header("About")
                st.markdown("""
                ãƒ» ã“ã‚“ã«ã¡ã¯ï¼ã“ã®ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã¯ã€ã•ã¾ã–ã¾ãªæ©Ÿèƒ½ã‚’å‚™ãˆã¦ã„ã¾ã™ã€‚  
                ãƒ» ã©ã‚“ãªã“ã¨ã§ã‚‚æ°—è»½ã«è©±ã—ã‹ã‘ã¦ãã ã•ã„ã­ğŸ˜Š  
                ãƒ» è‹±ä¼šè©±ã‚’ç·´ç¿’ã—ãŸã„æ™‚ã¯ã€ç”»åƒã‚’é€ä¿¡ã—ã¦ãã ã•ã„ï¼ğŸ“¸
                ã©ã‚“ãªè³ªå•ã§ã‚‚ãŠæ°—è»½ã«ã©ã†ãï¼ğŸ—£ï¸
                """, unsafe_allow_html=True)
                    
                
                if st.button("ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¯ãƒªã‚¢"):
                    st.session_state.chat_history.clear_history()
                    st.session_state.messages = []
                    MAX_MEMORY_LIMIT = 0
                    st.session_state.memory.chat_memory.messages = st.session_state.memory.chat_memory.messages[-MAX_MEMORY_LIMIT:]
                    st.session_state.memory = ConversationBufferMemory()

                # ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ã‚’ä¸‹ã«é…ç½®
                st.session_state.uploaded_file = st.file_uploader("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["png", "jpg", "jpeg"])
        
        # Show user info if logged in
        if st.session_state.get("authenticated"):
            st.write("---")
            st.write(f"### ãƒ¦ãƒ¼ã‚¶ãƒ¼ / User")
            st.write(f"ğŸ§‘â€ğŸ’» {st.session_state.user['username']}")
            if st.button("ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ / Logout"):
                st.session_state.clear()
                st.rerun()

import streamlit as st
from audio_recorder_streamlit import audio_recorder
from tempfile import NamedTemporaryFile
import ffmpeg
import io
import edge_tts
from edge_tts import VoicesManager
import random
import asyncio
from langchain.prompts import PromptTemplate
import re
import os
from diffusers import StableDiffusionPipeline, PNDMScheduler
from safetensors.torch import load_file
from PIL import Image
import time
from langchain_ollama import ChatOllama
from langchain.schema import HumanMessage, SystemMessage, AIMessage, BaseMessage

import torch
from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline

device = "cuda:1" if torch.cuda.is_available() else "cpu"

# éŸ³å£°ç”Ÿæˆã®ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
TTS_PROMPT = """
ã‚ãªãŸã¯ä¸ãˆã‚‰ã‚ŒãŸæ–‡ç« ã«å¯¾ã—ã¦ã€ä»¥ä¸‹ã®åˆ¤æ–­ã‚’è¡Œã†ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ï¼š
1. ã“ã®è¨€èªãŒæ—¥æœ¬èªãªã®ã‹è‹±èªãªã®ã‹

æ–‡ç« : {prompt}

ä»¥ä¸‹ã®å½¢å¼ã§å¿œç­”ã—ã¦ãã ã•ã„ï¼š
language_jp: [true/false] - è‹±èªãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯false
"""

level_prompt = """
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è‹±èªãƒ¬ãƒ™ãƒ«: {user_level}
ã“ã®ãƒ¬ãƒ™ãƒ«ã«é©ã—ãŸä¼šè©±ç·´ç¿’å•é¡Œã‚’è¡Œã„ãŸã„ã§ã™ã€‚
ãƒˆãƒ”ãƒƒã‚¯ã‚’1ã¤è€ƒãˆã€ä½•ã‹è³ªå•ã‹å•ã„ã‹ã‘ã‚’ç§ã«ã—ã¦ãã ã•ã„ã€‚ãƒ¬ãƒ™ãƒ«ã«åˆã‚ã›ã¦æ—¥æœ¬èªè¨³ãªã©ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚

ãƒˆãƒ”ãƒƒã‚¯: 

è³ªå•: 

ç­”ãˆã®ä¾‹: 
ã¨ã„ã£ãŸå½¢å¼ã«ã—ã¦ãã ã•ã„

### ä¾‹ (ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è‹±èªãƒ¬ãƒ™ãƒ«:Begginerã®å ´åˆ):
ãƒˆãƒ”ãƒƒã‚¯: é£Ÿã¹ç‰©

è³ªå•: What is your favorite food? (ã‚ãªãŸã®ãŠæ°—ã«å…¥ã‚Šã®é£Ÿã¹ç‰©ã¯ä½•ã§ã™ã‹ï¼Ÿ)

ç­”ãˆã®ä¾‹: My favorite food is sushi. (ç§ã®å¥½ããªé£Ÿã¹ç‰©ã¯å¯¿å¸ã§ã™ã€‚)

ã‚ãªãŸã®ç•ªã§ã™ï¼ã‚ãªãŸã®ãŠæ°—ã«å…¥ã‚Šã®é£Ÿã¹ç‰©ã¯ä½•ã§ã™ã‹ï¼Ÿ

"""
llm = ChatOllama(
    base_url="http://host.docker.internal:11434/",
    #llama3.1:8b
    #llama3.2:latest
    #7shi/tanuki-dpo-v1.0:latest
    model="gemma2:9b"
)

def convert_audio_format(audio_bytes, target_format="mp3"):
    import ffmpeg
    from tempfile import NamedTemporaryFile
    
    with NamedTemporaryFile(delete=True, suffix=".wav") as temp_file:
        temp_file.write(audio_bytes)
        temp_file.flush()

        with NamedTemporaryFile(delete=True, suffix=f".{target_format}") as converted_file:
            try:
                # overwrite_output() ã‚’è¿½åŠ 
                ffmpeg.input(temp_file.name).output(converted_file.name).overwrite_output().run()
                # å¤‰æ›ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’è¿”ã™
                return converted_file.read()
            except ffmpeg._run.Error as e:
                #print("FFmpeg error:", e.stderr)  # æ¨™æº–ã‚¨ãƒ©ãƒ¼å‡ºåŠ›ã‚’è¡¨ç¤º
                raise


        
def transcribe_audio_to_text(audio_bytes):
    try:
        with NamedTemporaryFile(delete=True, suffix=".wav") as temp_file:
            temp_file.write(audio_bytes)
            temp_file.flush()
            result = stt_model(
                temp_file.name
            )
            response = result["text"]
            return response
    except Exception as e:
        st.error(f"Error transcribing audio: {e}")
        return None
    

# Text-to-Speech function
async def text_to_speech(text,language="ja"):
    try:
        voices = await VoicesManager.create()  # éåŒæœŸé–¢æ•°ã¨ã—ã¦å‘¼ã³å‡ºã™
        voice = voices.find(Gender="Female", Language=language)
        
        # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã”ã¨ã«ä½œæˆ
        if 'tts_audio_path' not in st.session_state:
            temp_file = NamedTemporaryFile(delete=False, suffix=".mp3")
            st.session_state.tts_audio_path = temp_file.name

        # ãƒ•ã‚¡ã‚¤ãƒ«ã«éŸ³å£°ã‚’ä¿å­˜
        communicate = edge_tts.Communicate(text, random.choice(voice)["Name"])
        await communicate.save(st.session_state.tts_audio_path)  # éåŒæœŸã§ä¿å­˜

        return st.session_state.tts_audio_path  # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’è¿”ã™
    except Exception as e:
        st.error(f"Error converting text to speech: {e}")
        return None
    
# Generate text using Groq
def generate_text(prompt):
    try:
        messages = [
            SystemMessage(content="You are a helpful assistant."),
            HumanMessage(content=prompt)
        ]

        # Use the invoke method for chat completions
        response = llm.invoke(messages)
        # Extract and return the generated response from the model
        return response.content
    except Exception as e:
        st.error(f"Error generating text: {e}")
        return None
    
class Monster:
    def __init__(self, name):
        self.name = name
        self.level = 1
        self.exp = 0
        self.hp = 100
        self.strength = 10
        self.image = None

    def feed(self):
        self.exp += 20
        if self.exp >= 100:
            self.level_up()
    
    def level_up(self):
        self.level += 1
        self.exp = 0
        self.hp += 20
        self.strength += 5
        return True
    
    def to_dict(self):
        return {
            "name": self.name,
            "level": self.level,
            "exp": self.exp,
            "hp": self.hp,
            "strength": self.strength
        }

@st.cache_resource     
def download_and_save_models(save_dir="./models"):
    os.makedirs(save_dir, exist_ok=True)

    
    stdmodel_id = "stable-diffusion-v1-5/stable-diffusion-v1-5"
    stdmodel = StableDiffusionPipeline.from_pretrained(
        stdmodel_id,
        torch_dtype=torch.float16
    )
    StableDef_model_path = os.path.join(save_dir, "STD_model")
    stdmodel.save_pretrained(StableDef_model_path)
    
    # Mstdmodel_id = "lambdalabs/sd-pokemon-diffusers"
    # monsterstdmodel = StableDiffusionPipeline.from_pretrained(
    #     Mstdmodel_id,
    #     torch_dtype=torch.float16
    # )
    # monsterStableDef_model_path = os.path.join(save_dir, "STD_model1")
    # monsterstdmodel.save_pretrained(monsterStableDef_model_path)
    
    
    sttmodel_id = "openai/whisper-large-v3-turbo"
    sttmodel = AutoModelForSpeechSeq2Seq.from_pretrained(
        sttmodel_id,
        torch_dtype=torch.float16,
        low_cpu_mem_usage=True,
        use_safetensors=True
    )
    processor = AutoProcessor.from_pretrained(sttmodel_id)

    stt_model = pipeline(
        "automatic-speech-recognition",
        model=sttmodel,
        tokenizer=processor.tokenizer,
        feature_extractor=processor.feature_extractor,
        torch_dtype=torch.float16,
        device=device,
    )
    stt_model_path = os.path.join(save_dir, "STT_model")
    stt_model.save_pretrained(stt_model_path)
    
    
    #return monsterStableDef_model_path, StableDef_model_path, stt_model_path
    return StableDef_model_path, stt_model_path

@st.cache_resource(show_spinner="ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...", max_entries=1)
def load_saved_models(StableDef_model_path, stt_model_path):
    """
    ä¿å­˜ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€é–¢æ•°
    """
    #stdmodel
    # monsterstdmodel = StableDiffusionPipeline.from_pretrained(
    #     pretrained_model_name_or_path=monsterStableDef_model_path,
    #     torch_dtype=torch.float16
    # ).to(device)
    
    stdmodel = StableDiffusionPipeline.from_pretrained(
        pretrained_model_name_or_path=StableDef_model_path,
        torch_dtype=torch.float16
    ).to(device)
    
    # LoRAã®ãƒ­ãƒ¼ãƒ‰
    lora_path = "./models/pokemon_v3_offset.safetensors"
    lora_weights = load_file(lora_path)

    # LoRAã‚’ãƒ¢ãƒ‡ãƒ«ã«é©ç”¨
    def apply_lora(pipe, lora_weights, alpha=1.0):
        for name, param in pipe.unet.named_parameters():
            if name in lora_weights:
                param.data += alpha * lora_weights[name].data

    apply_lora(stdmodel, lora_weights)

    # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã®è¨­å®š
    stdmodel.scheduler = PNDMScheduler.from_config(stdmodel.scheduler.config)

    #sttmodel

    stt_model = pipeline(
        "automatic-speech-recognition",
        model=stt_model_path,
        torch_dtype=torch.float16,
        device=device,
    )
    
    # return monsterstdmodel,stdmodel,stt_model
    return stdmodel,stt_model

@st.cache_resource(show_spinner="stdãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...", max_entries=1)
def load_saved_stdmodels():
    """
    ä¿å­˜ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€é–¢æ•°
    """
    StableDef_model_path = "./models/anylora_diffusers_model"
    
    stdmodel = StableDiffusionPipeline.from_pretrained(
        pretrained_model_name_or_path=StableDef_model_path,
        torch_dtype=torch.float16
    ).to(device)
    
    # LoRAã®ãƒ­ãƒ¼ãƒ‰
    lora_path = "./models/pokemon_v3_offset.safetensors"
    lora_weights = load_file(lora_path)

    # LoRAã‚’ãƒ¢ãƒ‡ãƒ«ã«é©ç”¨
    def apply_lora(pipe, lora_weights, alpha=1.0):
        for name, param in pipe.unet.named_parameters():
            if name in lora_weights:
                param.data += alpha * lora_weights[name].data

    apply_lora(stdmodel, lora_weights)

    # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã®è¨­å®š
    stdmodel.scheduler = PNDMScheduler.from_config(stdmodel.scheduler.config)
    
    # return monsterstdmodel,stdmodel,stt_model
    return stdmodel

@st.cache_resource(show_spinner="sttãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...", max_entries=1)
def load_saved_sttmodels():
    """
    ä¿å­˜ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€é–¢æ•°
    """
    stt_model_path = "./models/STT_model"
    stt_model = pipeline(
        "automatic-speech-recognition",
        model=stt_model_path,
        torch_dtype=torch.float16,
        device=device,
    )
    
    # return monsterstdmodel,stdmodel,stt_model
    return stt_model

@st.cache_resource
def download_and_save_models_if_needed():
    # ãƒ¢ãƒ‡ãƒ«ãŒä¿å­˜ã•ã‚Œã‚‹ãƒ‘ã‚¹
    std_path = "./models/anylora_diffusers_model"
    #Mstd_path = "./models/STD_model1"
    stt_path = "./models/STT_model"
    
    # åˆæœŸåŒ–
    #monsterStableDef_model_path = Mstd_path
    StableDef_model_path = std_path
    stt_model_path = stt_path

    # ã‚‚ã—ãƒ¢ãƒ‡ãƒ«ãŒå­˜åœ¨ã—ãªã‘ã‚Œã°ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¨ä¿å­˜ã‚’å®Ÿè¡Œ
    if not os.path.exists(std_path) or not os.path.exists(stt_path):
        print("ãƒ¢ãƒ‡ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’é–‹å§‹ã—ã¾ã™ã€‚")
        StableDef_model_path, stt_model_path = download_and_save_models()
    else:
        print("ãƒ¢ãƒ‡ãƒ«ã¯ã™ã§ã«å­˜åœ¨ã—ã¦ã„ã¾ã™ã€‚ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¯ä¸è¦ã§ã™ã€‚")
        print("torch Num GPUs Available: ", torch.cuda.device_count())
        
    #return monsterStableDef_model_path, StableDef_model_path, stt_model_path    
    return StableDef_model_path, stt_model_path 
    
# åˆå›ã®ã¿å®Ÿè¡Œ
#monsterStableDef_model_path, StableDef_model_path, stt_model_path = download_and_save_models_if_needed()
#StableDef_model_path, stt_model_path = download_and_save_models_if_needed()
  
# ä¿å­˜ã—ãŸãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
#monsterstdmodel, stdmodel, stt_model = load_saved_models(monsterStableDef_model_path, StableDef_model_path, stt_model_path)
if 'models' not in st.session_state:
    #stdmodel = load_saved_stdmodels()
    #stt_model = load_saved_sttmodels()
    st.session_state.models = True

async def generate_monster_image(prompt,negative_prompt):
    try:
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«åŸºã¥ã„ã¦ç”»åƒã‚’ç”Ÿæˆ
        image = stdmodel(
            prompt=prompt,  # æ­£ã—ã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å¼•æ•°
            negative_prompt=negative_prompt,
            num_inference_steps=40,
            guidance_scale=7.5
        ).images[0]
        return image
    except Exception as e:
        st.error(f"ç”»åƒç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None
    
# async def generate_image(prompt,negative_prompt):
#     try:
#         # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«åŸºã¥ã„ã¦ç”»åƒã‚’ç”Ÿæˆ
#         image = stdmodel(
#             prompt=prompt,  # æ­£ã—ã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å¼•æ•°
#             negative_prompt=negative_prompt,
#             num_inference_steps=20,
#             guidance_scale=7.5
#         ).images[0]
#         return image
#     except Exception as e:
#         st.error(f"ç”»åƒç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
#         return None

def Monster_page():
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    if 'monster' not in st.session_state:
        st.session_state.monster = None
        st.session_state.element = None
        st.session_state.monster_type = None
    
    # ãƒ¢ãƒ³ã‚¹ã‚¿ãƒ¼ä½œæˆãƒ•ã‚©ãƒ¼ãƒ 
    if st.session_state.monster is None:
        with st.form("create_monster"):
            monster_name = st.text_input("ãƒ¢ãƒ³ã‚¹ã‚¿ãƒ¼ã®åå‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            monster_type = st.selectbox(
                "ãƒ¢ãƒ³ã‚¹ã‚¿ãƒ¼ã®ã‚¿ã‚¤ãƒ—ã‚’é¸æŠ",
                ["dragon", "slime", "fairy", "rock monster"]
            )
            
            # å±æ€§ã®è¿½åŠ 
            element = st.selectbox(
                "ãƒ¢ãƒ³ã‚¹ã‚¿ãƒ¼ã®å±æ€§ã‚’é¸æŠ",
                ["fire", "water", "grass", "electric"]
            )
            
            submit = st.form_submit_button("ãƒ¢ãƒ³ã‚¹ã‚¿ãƒ¼ã‚’ä½œæˆ")
            
            if submit and monster_name:
                st.session_state.monster = Monster(monster_name)
                st.session_state.element = element
                st.session_state.monster_type = monster_type
                with st.spinner("ãƒ¢ãƒ³ã‚¹ã‚¿ãƒ¼ã‚’ç”Ÿæˆä¸­..."):
                    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä½œæˆ
                    #prompt = f"a cute {element} type {monster_type} pokemon, simple design, white background, masterpiece"
                    prompt= f"a cute {element} type {monster_type} fantasy one monster, resembling a PokÃ©mon, small and chubby, with bright and colorful fur, large sparkling eyes, a happy expression, highly detailed, anime-inspired style, soft shading, vibrant colors"
                    negative_prompt="realistic, horror, scary, creepy, low quality, blurry, dull colors"
                    image = asyncio.run(generate_monster_image(prompt,negative_prompt))
                    if image:
                        st.session_state.monster.image = image
    
    # ãƒ¢ãƒ³ã‚¹ã‚¿ãƒ¼æƒ…å ±ã®è¡¨ç¤ºã¨æ“ä½œ
    #with st.sidebar:
    if st.session_state.monster:
        col1, col2 = st.columns(2)
        
        with col1:
            if st.session_state.monster.image:
                st.image(st.session_state.monster.image, caption=st.session_state.monster.name)
        
        with col2:
            st.write(f"åå‰: {st.session_state.monster.name}")
            st.progress(st.session_state.monster.exp / 100)
            st.write(f"ãƒ¬ãƒ™ãƒ«: {st.session_state.monster.level}")
            st.write(f"çµŒé¨“å€¤: {st.session_state.monster.exp}/100")
            st.write(f"HP: {st.session_state.monster.hp}")
            st.write(f"åŠ›: {st.session_state.monster.strength}")
        
        # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒœã‚¿ãƒ³
        col3, col4 = st.columns(2)
        with col3:
            if st.button("é¤Œã‚’ã‚ã’ã‚‹"):
                st.session_state.monster.feed()
                if st.session_state.monster.exp == 0:  # ãƒ¬ãƒ™ãƒ«ã‚¢ãƒƒãƒ—ã—ãŸå ´åˆ
                    st.balloons()
                    with st.spinner("ãƒ¢ãƒ³ã‚¹ã‚¿ãƒ¼ãŒé€²åŒ–ä¸­..."):
                        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‹ã‚‰å±æ€§ã¨ã‚¿ã‚¤ãƒ—ã‚’å–å¾—
                        element = st.session_state.element
                        monster_type = st.session_state.monster_type
                        # é€²åŒ–æ™‚ã¯ã‚ˆã‚Šå¼·ãã†ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨
                        prompt = f"a powerful evolved {element} type {monster_type} fantasy one monster, resembling a PokÃ©mon, small and chubby, with bright and colorful fur, large sparkling eyes, a happy expression, highly detailed, anime-inspired style, soft shading, vibrant colors, detailed features"
                        negative_prompt="realistic, creepy, low quality, blurry"
                        new_image = asyncio.run(generate_monster_image(prompt,negative_prompt))
                        if new_image:
                            st.session_state.monster.image = new_image
                st.rerun()
        
        with col4:
            if st.button("ãƒªã‚»ãƒƒãƒˆ"):
                st.session_state.monster = None
                st.session_state.element = None
                st.session_state.monster_type = None
                st.rerun()


def STT():
    st.title("Voice to Text Transcription")

    # åˆæœŸåŒ–
    if 'user_level' not in st.session_state:
        st.session_state.user_level = "Usual"
    if 'skip_first_attempt' not in st.session_state:
        st.session_state.skip_first_attempt = True
    if 'flag' not in st.session_state:
        st.session_state.flag = False
    if 'content' not in st.session_state:
        st.session_state.content = ""
    if 'audioflag' not in st.session_state:
        st.session_state.audioflag = False
    if 'prompt' not in st.session_state:
        st.session_state.prompt = None
    if 'reset_audio_input' not in st.session_state:
        st.session_state.reset_audio_input = False
    
    

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼: é›£æ˜“åº¦é¸æŠ & æ–°ã—ã„å•é¡Œç”Ÿæˆãƒœã‚¿ãƒ³
    # levels = st.sidebar.radio(
    #     "ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³",
    #     ["é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ (usual)", "åˆå¿ƒè€… (Beginner)", "ä¸­ç´šè€… (Intermediate)", "ä¸Šç´šè€… (Advanced)","Monster"],
    #     index=0,
    #     key="difficulty_radio"
    # )
    
    # with st.sidebar:
    #     if st.button("æ–°ã—ã„å•é¡Œã‚’ç”Ÿæˆ"):
    #         # å•é¡Œå†ç”Ÿæˆæ™‚ã«çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
    #         st.session_state.flag = False
    #         st.session_state.prompt = None
    #         st.session_state.reset_audio_input = True
        #st.markdown(st.session_state.levels)
    # ãƒ¬ãƒ™ãƒ«åˆ¥ã‚¿ã‚¹ã‚¯ç”Ÿæˆ
    if st.session_state.levels == "é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ (usual)":
        user_level = "Usual"
    elif st.session_state.levels == "åˆå¿ƒè€… (Beginner)":
        user_level = "Beginner"
    elif st.session_state.levels == "ä¸­ç´šè€… (Intermediate)":
        user_level = "Intermediate"
    elif st.session_state.levels == "ä¸Šç´šè€… (Advanced)":
        user_level = "Advanced" 
    elif st.session_state.levels == "è‚²æˆ":
        user_level = "Monster" 
    else:
        user_level = "Usual"
    
    if user_level=="Monster":
        Monster_page()
    else:
        # é›£æ˜“åº¦å¤‰æ›´æ™‚ã®çŠ¶æ…‹ãƒªã‚»ãƒƒãƒˆ
        if user_level != st.session_state.user_level:
            st.session_state.user_level = user_level
            st.session_state.flag = False
            st.session_state.prompt = None
            st.session_state.reset_audio_input = True
        
        #groq_client = ChatGroq(model_name="llama-3.1-70b-versatile")
        ollama_client = llm
        tts_prompt = PromptTemplate(template=TTS_PROMPT, input_variables=["prompt"])
        tts_chain = tts_prompt | ollama_client
        level_prompts = PromptTemplate(template=level_prompt, input_variables=["user_level"])
        level_chain = level_prompts | ollama_client

        # é›£æ˜“åº¦åˆ¥ã‚¿ã‚¹ã‚¯ç”Ÿæˆ
        if st.session_state.user_level == "Usual":
            st.write("è©±ã—ã‹ã‘ã¦ã¿ã‚ˆã†ï¼")
        else:
            if not st.session_state.flag:
                question_prompts = asyncio.run(level_chain.ainvoke(st.session_state.user_level))
                st.session_state.content = question_prompts.content if hasattr(question_prompts, 'content') else str(question_prompts)
            if st.session_state.content:
                st.write(st.session_state.content)
            st.session_state.flag = True

        # éŸ³å£°éŒ²éŸ³ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆ
        audio_bytes = audio_recorder(
            text="",
            recording_color="#e8b62c",
            neutral_color="#6aa36f",
            icon_name="microphone",
            icon_size="3x",
            pause_threshold=4
        )
        # st.markdown(st.session_state.reset_audio_input)

        # ãƒã‚¤ã‚¯æ¨©é™ã®ãŸã‚åˆå›ã‚’ã‚¹ã‚­ãƒƒãƒ—
        if st.session_state.skip_first_attempt:
            if audio_bytes:
                st.warning("Skipping first attempt to allow microphone permissions.")
                st.session_state.skip_first_attempt = False
            return  # åˆå›ã¯ä½•ã‚‚ã—ãªã„

        # éŸ³å£°å…¥åŠ›ã®ãƒªã‚»ãƒƒãƒˆãƒ•ãƒ©ã‚°ãŒTrueã®å ´åˆã€éŸ³å£°å…¥åŠ›ã‚’ã‚¯ãƒªã‚¢
        if st.session_state.reset_audio_input:
            audio_bytes = None
            st.session_state.reset_audio_input = False


        # éŸ³å£°ãƒ‡ãƒ¼ã‚¿å‡¦ç†
        if audio_bytes:
            audio_bytes = convert_audio_format(audio_bytes, target_format="mp3")
            transcript = transcribe_audio_to_text(audio_bytes)
            st.session_state.prompt = transcript
            if st.session_state.prompt:
                st.write("Transcribed Text:", st.session_state.prompt)
                # ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
                if st.session_state.user_level == "Usual":
                    generated_text = generate_text(st.session_state.prompt)
                else:
                    generated_text = generate_text(f"{st.session_state.content}ã®è³ªå•ã‚’ã‚‚ã¨ã«è¿”ç­”ã—ã¦ã„ã¾ã™ã€‚ä»¥ä¸‹ã®ç™ºè©±ã®è‹±èªã¨ã—ã¦ã®æ­£ç¢ºæ€§ã‚’è©•ä¾¡ã—ã€æ”¹å–„ç‚¹ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚:\n{st.session_state.prompt}")
                
                if generated_text:
                    st.write("Generated Text:")
                    st.write(generated_text)

                    # è¨€èªåˆ¤å®šã¨éŸ³å£°ç”Ÿæˆ
                    tts_result = asyncio.run(tts_chain.ainvoke(generated_text))
                    tts_content = tts_result.content if hasattr(tts_result, 'content') else str(tts_result)
                    language_flag = "language_jp: true" in tts_content
                    language = "ja" if language_flag else "en"

                    # éŸ³å£°ç”Ÿæˆ
                    audio_path = asyncio.run(text_to_speech(generated_text, language))
                    if audio_path:
                        st.audio(audio_path, format='audio/mpeg')
                        try:
                            os.remove(audio_path)
                            print("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒå‰Šé™¤ã•ã‚Œã¾ã—ãŸã€‚")
                        except FileNotFoundError:
                            print("å‰Šé™¤ã—ã‚ˆã†ã¨ã—ãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                        except Exception as e:
                            print(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

def reset_mode_specific_state(mode):
    """
    Resets states specific to each mode to prevent UI or data conflicts.
    """
    #if mode == "study":
        # Reset study mode specific states
        # st.session_state.selected_words = []
        # st.session_state.learnimage = None
        # st.session_state.Flag_serachimag = False
        # st.session_state.generate_toggle = False
    #elif mode == "chat":
        # Reset chat mode specific states
        # st.session_state.messages = []
        # st.session_state.chat_history = None
    #elif mode == "stt":
        # Reset STT mode specific states
        # st.session_state.levels = "é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ (usual)"
        # st.session_state.prompt = None
        # st.session_state.reset_audio_input = True

def main():
    st.session_state.image_flag = None
    # Initialize database
    init_db()
    
    # Set default mode if not set
    if 'mode' not in st.session_state:
        st.session_state.mode = "study"
    if 'Flag_serachimag' not in st.session_state:
        st.session_state.Flag_serachimag = False
    if 'image_results' not in st.session_state:
        st.session_state.image_results = []
    if 'image_results' not in st.session_state:
        st.session_state.image_results = []
    if 'learnimage' not in st.session_state:
            st.session_state.learnimage = None
    if 'generate_toggle' not in st.session_state:
        st.session_state.generate_toggle = False
    # if 'last_mode' not in st.session_state:
    #     st.session_state.last_mode = None

    # Check if mode has changed
    # if st.session_state.mode != st.session_state.last_mode:
    #     reset_mode_specific_state(st.session_state.mode)
    #     st.session_state.last_mode = st.session_state.mode
    
    # Create sidebar
    create_sidebar()
    
    # Check authentication
    if 'authenticated' not in st.session_state or not st.session_state.authenticated:
        show_auth_ui()
    else:
        # Display appropriate UI based on mode
        if st.session_state.mode == "study":
            if 'current_sentence' not in st.session_state:
                generate_new_sentence()
            create_app_ui()
        elif st.session_state.mode == "chat":
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
            init_session_state()

            # DuckDuckGoæ¤œç´¢ã®åˆæœŸåŒ–
            st.session_state.search = DuckDuckGoSearchAPIWrapper(
                backend="api",
                max_results=5,
                region="jp-jp",
                safesearch="off",
                source="text",
                time="w"
            )
            create_chat_ui()
        elif st.session_state.mode == "stt":
            STT()

if __name__ == "__main__":
    main()